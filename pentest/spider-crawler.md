# Spider / crawler

## Collections

Uncategorized

* [devanshbatham/ParamSpider - Mining parameters from dark corners of Web Archives](https://github.com/devanshbatham/ParamSpider)
* [Nekmo/dirhunt - Find web directories without bruteforce - 有个index of自动识别功能](https://github.com/Nekmo/dirhunt)
* [fcavallarin/htcap - a web application scanner able to crawl single page application (SPA) in a recursive manner by intercepting ajax calls and DOM changes](https://github.com/fcavallarin/htcap)
* [GerbenJavado/LinkFinder - A python script that finds endpoints in JavaScript files - 支持burpsuite导出的文件](https://github.com/GerbenJavado/LinkFinder)
* [nahamsec/JSParser - A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests when performing security research or bug bounty hunting](https://github.com/nahamsec/JSParser)
* [OWASP zaproxy - AJAX Spider site](https://github.com/zaproxy/zaproxy)
* [danielmiessler/RobotsDisallowed - A harvest of the Disallowed directories from the robots.txt files of the world's top websites](https://github.com/danielmiessler/RobotsDisallowed)
* [milo2012/pathbrute - Pathbrute is a DirB/Dirbuster type of tool designed to brute force directories and files names on web/application servers](https://github.com/milo2012/pathbrute)
* [maurosoria/dirsearche - Web path scanner](https://github.com/maurosoria/dirsearch)
* [s0md3v/Photon - Incredibly fast crawler which extracts urls, emails, files, website accounts and much more](https://github.com/s0md3v/Photon)
* [si9int/cc.py - Extracting URLs of a specific target based on the results of "commoncrawl.org"](https://github.com/si9int/cc.py)
* [jordanpotti/CloudScraper - a Tool to spider and scrape targets in search of cloud resources](https://github.com/jordanpotti/CloudScraper)
* [facert/awesome-spider - 爬虫集合](https://github.com/facert/awesome-spider)
* [Anorov/cloudflare-scrape - A Python module to bypass Cloudflare's anti-bot page](https://github.com/Anorov/cloudflare-scrape)

Chrome headless
 
* [yujiosaka/headless-chrome-crawler - Distributed crawler powered by Headless Chrome](https://github.com/yujiosaka/headless-chrome-crawler)
* [0Kee-Team/crawlergo - A powerful dynamic crawler for web vulnerability scanners](https://github.com/0Kee-Team/crawlergo)
* [ring04h/papers - WEB2.0启发式爬虫实战-猪猪侠-20180616 - 关闭xss auditor + 自定义函数检测dom xss/拦截请求以防止意外跳转/劫持XHR/监控DOM变化/表单自动填充/隐身模式启动](https://github.com/ring04h/papers/blob/master/WEB2.0%E5%90%AF%E5%8F%91%E5%BC%8F%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98-%E7%8C%AA%E7%8C%AA%E4%BE%A0-20180616.pdf)
* [myvyang/chromium_for_spider - 为漏扫动态爬虫定制的浏览器](https://github.com/myvyang/chromium_for_spider)
* [adieuadieu/serverless-chrome - Run headless Chrome/Chromium on AWS Lambda](https://github.com/adieuadieu/serverless-chrome)
* [berstend/puppeteer-extra - Teach puppeteer new tricks through plugins](https://github.com/berstend/puppeteer-extra/tree/master/packages/puppeteer-extra)


